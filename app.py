import streamlit as st
import os
import tempfile
from dotenv import load_dotenv
from llama_parse import LlamaParse
from llama_index.core import SimpleDirectoryReader, Settings
from llama_index.llms.openai import OpenAI
from llama_index.core.program import LLMTextCompletionProgram
from pydantic import BaseModel, Field
from typing import List

# --- –ù–ê–°–¢–†–û–ô–ö–ò –°–¢–†–ê–ù–ò–¶–´ ---
st.set_page_config(page_title="AI Course Factory", page_icon="üéì", layout="wide")
load_dotenv()

# --- –°–¢–†–£–ö–¢–£–†–ê –î–ê–ù–ù–´–• ---
class QuizQuestion(BaseModel):
    scenario: str = Field(..., description="–û–ø–∏—Å–∞–Ω–∏–µ —Å–∏—Ç—É–∞—Ü–∏–∏")
    options: List[str] = Field(..., description="4 –≤–∞—Ä–∏–∞–Ω—Ç–∞ –æ—Ç–≤–µ—Ç–∞")
    correct_option_id: int = Field(..., description="–ò–Ω–¥–µ–∫—Å –ø—Ä–∞–≤–∏–ª—å–Ω–æ–≥–æ –æ—Ç–≤–µ—Ç–∞ (0-3)")
    explanation: str = Field(..., description="–û–±—ä—è—Å–Ω–µ–Ω–∏–µ")

class Quiz(BaseModel):
    questions: List[QuizQuestion]

# --- –ë–û–ö–û–í–ê–Ø –ü–ê–ù–ï–õ–¨ ---
with st.sidebar:
    st.header("‚öôÔ∏è –ù–∞—Å—Ç—Ä–æ–π–∫–∏")
    
    quiz_lang = st.selectbox(
        "–Ø–∑—ã–∫ —Ç–µ—Å—Ç–∞:",
        ["–†—É—Å—Å–∫–∏–π", "English", "“ö–∞–∑–∞“õ—à–∞", "O'zbekcha", "–ö—ã—Ä–≥—ã–∑—á–∞", "Espa√±ol", "Deutsch"],
        index=0
    )
    
    quiz_difficulty = st.radio(
        "–°–ª–æ–∂–Ω–æ—Å—Ç—å:",
        ["Easy (–§–∞–∫—Ç—ã)", "Hard (–ö–µ–π—Å—ã)"],
        index=1
    )
    
    quiz_count = st.slider("–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤–æ–ø—Ä–æ—Å–æ–≤:", 1, 10, 3)

# --- –û–°–ù–û–í–ù–û–ô –≠–ö–†–ê–ù ---
st.title("üéì AI Course Generator")

# –ë–ï–ó–û–ü–ê–°–ù–ê–Ø –ü–†–û–í–ï–†–ö–ê –ö–õ–Æ–ß–ï–ô
has_llama = bool(os.getenv("LLAMA_CLOUD_API_KEY"))
has_openai = bool(os.getenv("OPENAI_API_KEY"))

if has_llama and has_openai:
    st.success("‚úÖ –ö–ª—é—á–∏ –∞–∫—Ç–∏–≤–Ω—ã (Secure Mode)")
else:
    st.warning("‚ö†Ô∏è –ö–ª—é—á–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã. –í–≤–µ–¥–∏—Ç–µ –∏—Ö –≤—Ä—É—á–Ω—É—é:")
    new_llama = st.text_input("LlamaCloud Key", type="password")
    new_openai = st.text_input("OpenAI Key", type="password")
    
    if new_llama and new_openai:
        os.environ["LLAMA_CLOUD_API_KEY"] = new_llama
        os.environ["OPENAI_API_KEY"] = new_openai
        st.rerun()

# 1. –û–ë–ù–û–í–õ–ï–ù–ò–ï: –†–∞–∑—Ä–µ—à–∞–µ–º PDF –∏ PPTX
uploaded_file = st.file_uploader("–ó–∞–≥—Ä—É–∑–∏ –º–∞—Ç–µ—Ä–∏–∞–ª (PDF –∏–ª–∏ PPTX)", type=["pdf", "pptx"])

if uploaded_file:
    if st.button("üöÄ –°–æ–∑–¥–∞—Ç—å –¢–µ—Å—Ç"):
        
        if not os.environ.get("LLAMA_CLOUD_API_KEY"):
            st.error("–ù–µ—Ç –∫–ª—é—á–µ–π!")
            st.stop()

        # 2. –û–ë–ù–û–í–õ–ï–ù–ò–ï: –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ —Ñ–∞–π–ª–∞ (.pdf –∏–ª–∏ .pptx)
        file_ext = os.path.splitext(uploaded_file.name)[1].lower()
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ–º
        with tempfile.NamedTemporaryFile(delete=False, suffix=file_ext) as tmp:
            tmp.write(uploaded_file.getvalue())
            tmp_path = tmp.name

        # 3. –ü–ê–†–°–ò–ù–ì
        with st.spinner("üìÑ –ß–∏—Ç–∞—é —Å–ª–∞–π–¥—ã –∏ —Ç–µ–∫—Å—Ç..."):
            try:
                # LlamaParse —Å–∞–º –ø–æ–π–º–µ—Ç —Ñ–æ—Ä–º–∞—Ç
                parser = LlamaParse(result_type="markdown", language="ru", api_key=os.environ["LLAMA_CLOUD_API_KEY"])
                
                # –Ø–≤–Ω–æ –≥–æ–≤–æ—Ä–∏–º, –∫–∞–∫–æ–π –ø–∞—Ä—Å–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –¥–ª—è –∫–∞–∫–∏—Ö —Ñ–∞–π–ª–æ–≤
                file_extractor = {".pdf": parser, ".pptx": parser}
                
                docs = SimpleDirectoryReader(input_files=[tmp_path], file_extractor=file_extractor).load_data()
                
                if not docs:
                    st.error("–û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è —Ñ–∞–π–ª–∞. –í–æ–∑–º–æ–∂–Ω–æ, –æ–Ω –ø—É—Å—Ç.")
                    st.stop()
                text = docs[0].text
            except Exception as e:
                st.error(f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞: {e}")
                st.stop()

        # 4. –ì–ï–ù–ï–†–ê–¶–ò–Ø
        with st.spinner(f"üß† –ê–Ω–∞–ª–∏–∑–∏—Ä—É—é –∫–æ–Ω—Ç–µ–Ω—Ç ({quiz_lang})..."):
            try:
                Settings.llm = OpenAI(model="gpt-4o", temperature=0.1)
                
                prompt = (
                    f"–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —ç—Ç–æ—Ç —É—á–µ–±–Ω—ã–π –º–∞—Ç–µ—Ä–∏–∞–ª. –°–æ–∑–¥–∞–π —Ç–µ—Å—Ç –Ω–∞ —è–∑—ã–∫–µ: {quiz_lang}. "
                    f"–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤–æ–ø—Ä–æ—Å–æ–≤: {quiz_count}. "
                    f"–°–ª–æ–∂–Ω–æ—Å—Ç—å: {quiz_difficulty}. "
                    "–ï—Å–ª–∏ —ç—Ç–æ –ø—Ä–µ–∑–µ–Ω—Ç–∞—Ü–∏—è, —É—á–∏—Ç—ã–≤–∞–π —Ç–µ–∫—Å—Ç –Ω–∞ —Å–ª–∞–π–¥–∞—Ö. "
                    "–í–µ—Ä–Ω–∏ –°–¢–†–û–ì–û JSON."
                )
                
                program = LLMTextCompletionProgram.from_defaults(
                    output_cls=Quiz,
                    prompt_template_str=prompt + " –¢–µ–∫—Å—Ç: {text}",
                    llm=Settings.llm
                )
                
                # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º –ª–∏–º–∏—Ç, —Ç–∞–∫ –∫–∞–∫ –ø—Ä–µ–∑–µ–Ω—Ç–∞—Ü–∏–∏ –±—ã–≤–∞—é—Ç –±–æ–ª—å—à–∏–º–∏
                result = program(text=text[:20000])
                st.session_state['quiz'] = result
            except Exception as e:
                st.error(f"–û—à–∏–±–∫–∞ AI: {e}")
                st.stop()

# --- –í–´–í–û–î ---
if 'quiz' in st.session_state:
    st.divider()
    for i, q in enumerate(st.session_state['quiz'].questions):
        st.subheader(f"{i+1}. {q.scenario}")
        st.radio("–í–∞—Ä–∏–∞–Ω—Ç—ã:", q.options, key=f"q{i}")
        with st.expander("–ü–æ–∫–∞–∑–∞—Ç—å –æ—Ç–≤–µ—Ç"):
            st.write(f"–ü—Ä–∞–≤–∏–ª—å–Ω–æ: {q.options[q.correct_option_id]}")
            st.info(q.explanation)